{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CX4240 project\n",
    "\n",
    "## Classification of Acute Lymphoblastic Leukemia (ALL) in Blood Cell Images Using Machine Learning\n",
    "\n",
    "# Feature Extractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stat\n",
    "import sklearn.preprocessing as pre\n",
    "import glob\n",
    "import mahotas as mt\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import csv \n",
    "import matplotlib as mpl\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(stage, fold=None, label=None):\n",
    "    \"\"\"\n",
    "    ARGS:    stage: 'train' or 'test'\n",
    "             fold: int\n",
    "             label: 'all' or 'hem'\n",
    "    returns: general file path for given inputs\n",
    "    \"\"\"\n",
    "    og_path = '/Users/1000j/CX4240+/Cell_Images/'\n",
    "    if stage == 'train':\n",
    "        return og_path + 'C-NMC_training_data/fold_' + str(fold) + '/' + label + '/*.bmp'\n",
    "    elif stage == 'test':\n",
    "        return og_path + 'C-NMC_test_prelim_phase_data/'*2 + '*.bmp'\n",
    "    else:\n",
    "        print('must enter \"train\" or \"test\"')\n",
    "        return\n",
    "\n",
    "def read_images(stage, fold=None, label=None):\n",
    "    \"\"\"\n",
    "    ARGS:    stage: 'train' or 'test'\n",
    "             fold: int\n",
    "             label: 'all' or 'hem'\n",
    "    returns: color: list of all color images\n",
    "             gray: list of all gray images\n",
    "             ids: list of associated image ids\n",
    "    \"\"\"\n",
    "    \n",
    "    img_path = find_path(stage, fold, label)\n",
    "    start = len(img_path) - 5\n",
    "    color, gray, ids = [], [], []\n",
    "    ids = []\n",
    "    for name in glob.glob(img_path):\n",
    "        ids.append(name[start : -4])\n",
    "        color.append(cv2.imread(name))\n",
    "        gray.append(cv2.imread(name,0))\n",
    "    color = np.array(color)\n",
    "    gray = np.array(gray)\n",
    "    ret, binary = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "    if stage=='train':\n",
    "        print('done loading training %s images in fold%s' % (label,str(fold)))\n",
    "    else:\n",
    "        print('done loading test images')\n",
    "    return color, gray, binary, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading training all images in fold0\n",
      "done loading training hem images in fold0\n"
     ]
    }
   ],
   "source": [
    "# Load train images\n",
    "ALL_0_color, ALL_0_gray, ALL_0_binary, ALL_0_ids = read_images('train', 0, 'all')\n",
    "hem_0_color, hem_0_gray, hem_0_binary, hem_0_ids = read_images('train', 0, 'hem')\n",
    "ALL_1_color, ALL_1_gray, ALL_1_binary, ALL_1_ids = read_images('train', 1, 'all')\n",
    "hem_1_color, hem_1_gray, hem_1_binary, hem_1_ids = read_images('train', 1, 'hem')\n",
    "ALL_2_color, ALL_2_gray, ALL_2_binary, ALL_2_ids = read_images('train', 2, 'all')\n",
    "hem_2_color, hem_2_gray, hem_2_binary, hem_2_ids = read_images('train', 2, 'hem')\n",
    "ALL_0_color = np.concatenate((ALL_0_color,ALL_1_color,ALL_2_color), axis=0)\n",
    "ALL_0_gray = np.concatenate((ALL_0_gray,ALL_1_gray,ALL_2_gray), axis=0)\n",
    "ALL_0_binary = np.concatenate((ALL_0_binary,ALL_1_binary,ALL_2_binary), axis=0)\n",
    "hem_0_color = np.concatenate((hem_0_color,hem_1_color,hem_2_color), axis=0)\n",
    "hem_0_gray = np.concatenate((hem_0_gray,hem_1_gray,hem_2_gray), axis=0)\n",
    "hem_0_binary = np.concatenate((hem_0_binary,hem_1_binary,hem_2_binary), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "t_color, t_gray, t_binary, test_ids = read_images('test', 0)\n",
    "test_ids = np.asarray(test_ids, dtype=int)\n",
    "test_color = np.zeros(np.shape(t_color), dtype=np.uint8)\n",
    "test_gray = np.zeros(np.shape(t_gray), dtype=np.uint8)\n",
    "test_binary = np.zeros(np.shape(t_binary), dtype=np.uint8)\n",
    "test_color[test_ids-1] = t_color\n",
    "test_gray[test_ids-1] = t_gray\n",
    "test_binary[test_ids-1] = t_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images\n",
    "n_ALL = len(ALL_0_color)\n",
    "n_hem = len(hem_0_color)\n",
    "n_test = len(test_color)\n",
    "# Shape of images\n",
    "print(np.shape(ALL_0_color))\n",
    "print(np.shape(hem_0_color))\n",
    "print(np.shape(test_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(10, 8), dpi=160, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,3,1), plt.imshow(ALL_0_color[172]), plt.title('ALL color')\n",
    "plt.subplot(2,3,2), plt.imshow(ALL_0_gray[172],'gray'), plt.title('ALL grayscale')\n",
    "plt.subplot(2,3,3), plt.imshow(ALL_0_binary[172],'gray'), plt.title('ALL binary')\n",
    "plt.subplot(2,3,4), plt.imshow(hem_0_color[127]), plt.title('Normal color')\n",
    "plt.subplot(2,3,5), plt.imshow(hem_0_gray[127],'gray'), plt.title('Normal grayscale')\n",
    "plt.subplot(2,3,6), plt.imshow(hem_0_binary[127],'gray'), plt.title('Normal binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "for i, j in enumerate(np.random.randint(n_ALL, size = 5)):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(ALL_0_color[j])\n",
    "plt.suptitle('ALL Cells', fontsize=25)\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "for i, j in enumerate(np.random.randint(n_hem, size = 5)):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(hem_0_color[j])\n",
    "plt.suptitle('Normal Cells', fontsize=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "    F1: cell size\n",
    "    F2: perimeter\n",
    "    F3: form factor\n",
    "    F4: roundness\n",
    "    F5: length/diameter ratio\n",
    "    F6: compactness\n",
    "    F7-F9: contour signature of nucleus: \n",
    "        variance, skewness, and kurtosis of the distances between centroid and contour points\n",
    "    F10-F22: Haralick texture \n",
    "        angular second moment\n",
    "        contrast\n",
    "        correlation\n",
    "        variance\n",
    "        inverse difference moment\n",
    "        sum average\n",
    "        sum variance\n",
    "        sum entropy\n",
    "        difference entropy\n",
    "        information measures of correlation (F12, F13)\n",
    "    F23-30: Haar wavelet texture\n",
    "        Means and variances of low-pass filtered appriximation image \n",
    "        and high-pass filterd in horizontal, vertical, and diagonal directions\n",
    "    F31-F36: color features\n",
    "        Means in RGB\n",
    "        Means in HSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Cell Size','Perimeter','Form Factor','Roundness','Length/Diameter Ratio','Compactness',\n",
    "            'Boundary Roughness Variance','Boundary Roughness Skewness','Boundary Roughness Kurtosis',\n",
    "            'Haralick Angular Second Moment','Haralick Contrast','Haralick Correlation','Haralick Variance',\n",
    "            'Haralick Inverse Difference Moment','Haralick Sum Average','Haralick Sum Variance',\n",
    "            'Haralick Sum Entropy','Haralick Entropy','Haralick Difference Variance','Haralick Difference Entropy',\n",
    "            'Haralick Information Measures of Correlation 1','Haralick Information Measures of Correlation 2',\n",
    "            'Wavelet Approximation Mean','Wavelet Horizontal Mean','Wavelet Vertical Mean','Wavelet Diagonal Mean',\n",
    "            'Wavelet Approximation Variance', 'Wavelet Horizontal Variance','Wavelet Vertical Variance',\n",
    "            'Wavelet Diagonal Variance','Red Mean','Green Mean','Blue Mean','Hue Mean','Saturation Mean','Value Mean',\n",
    "            'Intensity Mean','Intensity Variance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological features\n",
    "def get_cell_size(image):\n",
    "    \"\"\"\n",
    "    ARGS:    \n",
    "        image: black and white image\n",
    "    returns:\n",
    "        size: the number of pixels in the cell\n",
    "    \"\"\"\n",
    "#    ret,thresh=cv2.threshold(image,THRESH,255,cv2.THRESH_BINARY)\n",
    "#    return cv2.countNonZero(image)\n",
    "    return np.count_nonzero(image, axis=(1,2))\n",
    "\n",
    "def get_cell_perimeter(image):\n",
    "    \"\"\"\n",
    "    ARGS:    \n",
    "        image: black and white image\n",
    "    returns:\n",
    "        perimeter: the number of pixels in the perimeter\n",
    "        cnt: x,y coordiantes of boundary (list)\n",
    "    \"\"\"\n",
    "#    ret,thresh = cv2.threshold(image,THRESH,255,cv2.THRESH_BINARY)\n",
    "    perimeter = np.zeros(len(image))\n",
    "    cnt = []\n",
    "    for i in range(len(image)):\n",
    "        _, contour, _ = cv2.findContours(image[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        perimeter[i] = contour[0].shape[0]\n",
    "        cnt.append(contour[0])\n",
    "    return perimeter, cnt\n",
    "\n",
    "def get_centeroid(image):\n",
    "    \"\"\"\n",
    "    arg:\n",
    "        image: binary image\n",
    "    returns:\n",
    "        cx: x coordinate of center\n",
    "        cy: y coordinate of center\n",
    "    \"\"\"\n",
    "    cx = np.zeros(len(image), dtype=int)\n",
    "    cy = np.zeros(len(image), dtype=int)\n",
    "    for i in range(len(image)):\n",
    "        M = cv2.moments(image[i])\n",
    "        cx[i] = int(M['m10']/M['m00'])\n",
    "        cy[i] = int(M['m01']/M['m00'])\n",
    "    return cx,cy\n",
    "    \n",
    "def get_diameter(image):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        image: binary images\n",
    "    returns: \n",
    "        major_d: the maximum diameter (number of pixels) on the major axis\n",
    "        minor_d: the diameter (number of pixels) on the minor axis (perpendicular to the major axis)\n",
    "        min_d: the minimum diameter \n",
    "    \"\"\"\n",
    "    (rows, cols) = image[0].shape[:2] \n",
    "    major_d = np.zeros(len(image))\n",
    "    minor_d = np.zeros(len(image))\n",
    "    min_d = rows*np.ones(len(image))\n",
    "    major_img = np.zeros(np.shape(image))\n",
    "    minor_img = np.zeros(np.shape(image))\n",
    "    for i in range(len(image)):\n",
    "        for ang in range(0,180,10):\n",
    "            # Images are rotated 0 to 170 degrees with the increment of 10 degrees\n",
    "            # getRotationMatrix2D creates a matrix needed for transformation. \n",
    "            M = cv2.getRotationMatrix2D((cols / 2, rows / 2), ang, 1) \n",
    "            rotated_img = cv2.warpAffine(image[i], M, (cols, rows))\n",
    "            temp_d = np.count_nonzero(rotated_img[int(rows/2),:]) # count pixels\n",
    "            if temp_d > major_d[i]:\n",
    "                major_d[i] = temp_d\n",
    "                minor_d[i] = np.count_nonzero(rotated_img[:,int(cols/2)]) \n",
    "            if temp_d < min_d[i]:\n",
    "                min_d[i] = temp_d\n",
    "    return major_d, minor_d, min_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 size\n",
    "F1_all = get_cell_size(ALL_0_binary)\n",
    "F1_hem = get_cell_size(hem_0_binary)\n",
    "F1_t = get_cell_size(test_binary)\n",
    "#F2 perimeter\n",
    "F2_all, ALL_0_cnt = get_cell_perimeter(ALL_0_binary)\n",
    "F2_hem, hem_0_cnt = get_cell_perimeter(hem_0_binary)\n",
    "F2_t, test_cnt = get_cell_perimeter(test_binary)\n",
    "\n",
    "ALL_0_major_d, ALL_0_minor_d, ALL_0_min_d = get_diameter(ALL_0_binary)\n",
    "hem_0_major_d, hem_0_minor_d, hem_0_min_d = get_diameter(hem_0_binary)\n",
    "test_major_d, test_minor_d, test_min_d = get_diameter(test_binary)\n",
    "ALL_0_cx, ALL_0_cy = get_centeroid(ALL_0_binary)\n",
    "hem_0_cx, hem_0_cy = get_centeroid(hem_0_binary)\n",
    "test_cx, test_cy = get_centeroid(test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_form_factor(area, perimeter):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        area: the area of cell (cell size)\n",
    "        perimeter: the total number of pixels representing the cell boundary\n",
    "    returns: \n",
    "        form_factor: shape of cell\n",
    "    \"\"\"\n",
    "    return 4*np.pi*area/perimeter**2\n",
    "\n",
    "def get_roundness(area, major_diameter):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        area: the area of cell (cell size)\n",
    "        major_diameter: the diameter of cell on the major axis\n",
    "    returns: \n",
    "        roundness: the degree to which the cell shape differs from that of a circle\n",
    "    \"\"\"\n",
    "    return 4*area/(np.pi*major_diameter**2)\n",
    "\n",
    "def get_diameter_ratio(major_d, minor_d):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        major_d: the maximum diameter (number of pixels) on the major axis\n",
    "        minor_d: the diameter (number of pixels) on the minor axis (perpendicular to the major axis\n",
    "    returns: \n",
    "        ratio: ratio of major_d and minor_d\n",
    "    \"\"\"\n",
    "    return major_d/minor_d\n",
    "\n",
    "def get_compactness(area, major_diameter):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        area: area of cell (cell size)\n",
    "        major_diameter: the diameter of cell on the major axis\n",
    "    returns: \n",
    "        compactness: the degree to how compact the shape of cell is\n",
    "    \"\"\"\n",
    "    return ((4*area/np.pi)**(1/2))/major_diameter\n",
    "\n",
    "def get_contour_signature(image, cnt, cx, cy):\n",
    "    \"\"\" Boundary roughness\n",
    "    arg:\n",
    "        image: binary images\n",
    "        cnt: (list of numpy array ixjxk) x,y coordiantes of boundary\n",
    "        cx: x coordinate of center\n",
    "        cy: y coordinage of center\n",
    "    returns:\n",
    "        variance, skewness, kurtosis\n",
    "    \"\"\"\n",
    "    variance = np.zeros(len(image))\n",
    "    skewness = np.zeros(len(image))\n",
    "    kurtosis = np.zeros(len(image))\n",
    "    for i in range(len(image)):\n",
    "        xy = cnt[i]\n",
    "        norm2 = np.zeros(len(xy))\n",
    "        for j in range(len(xy)):\n",
    "            norm2[j] = np.linalg.norm((cx[i],cy[i])-xy[j,0,:])\n",
    "        variance[i] = np.var(norm2)\n",
    "        skewness[i] = stat.skew(norm2)\n",
    "        kurtosis[i] = stat.kurtosis(norm2)\n",
    "    return variance, skewness, kurtosis\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F3 form factor\n",
    "F3_all = get_form_factor(F1_all, F2_all)\n",
    "F3_hem = get_form_factor(F1_hem, F2_hem)\n",
    "F3_t = get_form_factor(F1_t, F2_t)\n",
    "#F4 roundness\n",
    "F4_all = get_roundness(F1_all, ALL_0_major_d)\n",
    "F4_hem = get_roundness(F1_hem, hem_0_major_d)\n",
    "F4_t = get_roundness(F1_t, test_major_d)\n",
    "#F5 diameter ratio\n",
    "F5_all = get_diameter_ratio(ALL_0_major_d, ALL_0_minor_d)\n",
    "F5_hem = get_diameter_ratio(hem_0_major_d, hem_0_minor_d)\n",
    "F5_t = get_diameter_ratio(test_major_d, test_minor_d)\n",
    "#F6 compactness\n",
    "F6_all = get_compactness(F1_all, ALL_0_major_d)\n",
    "F6_hem = get_compactness(F1_hem, hem_0_major_d)\n",
    "F6_t = get_compactness(F1_t, test_major_d)\n",
    "#F7-F9 variance, skewness, kurtosis (boundary roughness)\n",
    "F7_all, F8_all, F9_all = get_contour_signature(ALL_0_binary, ALL_0_cnt, ALL_0_cx, ALL_0_cy)\n",
    "F7_hem, F8_hem, F9_hem = get_contour_signature(hem_0_binary, hem_0_cnt, hem_0_cx, hem_0_cy)\n",
    "F7_t, F8_t, F9_t = get_contour_signature(test_binary, test_cnt, test_cx, test_cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture features\n",
    "def crop_image(image, cx, cy, min_d=50):\n",
    "    \"\"\"\n",
    "        args:\n",
    "            image: grayscale image\n",
    "            cx: x coordinate of center (row)\n",
    "            cy: y coordiante of center (column)\n",
    "            mid_d: (int) minimum diameter of all cells\n",
    "        returns:\n",
    "            new_img: cropped images with size min_d by min_d\n",
    "    \"\"\"\n",
    "    rows, cols = image[0].shape[:2] \n",
    "    l = np.int(np.min(min_d)/2)\n",
    "    for i in range(len(image)):\n",
    "        new_img = image[:,cx[i]-l:cx[i]+l,cy[i]-l:cy[i]+l]\n",
    "    return new_img\n",
    "\n",
    "def Haralick(img):\n",
    "    '''Haralick texture using Gray-level co-occurrence matrix (GLCM)\n",
    "    arg: \n",
    "        img: N number of MxM grayscale images\n",
    "    return: \n",
    "        Haralick_texture: Nx13 array with 13 features \n",
    "    '''\n",
    "    Haralick_texture = []\n",
    "    for i in range(len(img)):\n",
    "        feat = mt.features.haralick(img[i,:,:], return_mean=True, ignore_zeros=True)\n",
    "        Haralick_texture.append(feat)\n",
    "    Haralick_texture = np.array(Haralick_texture)     \n",
    "    return Haralick_texture\n",
    "    \n",
    "def Haar_wavelet(img):\n",
    "    '''Extract Haar wavelet texture features\n",
    "    Means and variances of low-pass filtered appriximation image \n",
    "    and high-pass filterd in horizontal, vertical, and diagonal directions\n",
    "    arg:\n",
    "        img: N number of MxM grayscale images\n",
    "    return: \n",
    "        Haar_wavelet_features: Nx8 array with 8 features\n",
    "            (cA_mean, cH_mean, cV_mean, cD_mean, cA_var, cH_var, cV_var, and cD_var)\n",
    "    '''\n",
    "    cA, (cH, cV, cD) = pywt.dwt2(img,'haar')\n",
    "    n = len(cA)\n",
    "    cA_mean = np.reshape(cA.mean(axis=(1,2)), (n,1))\n",
    "    cH_mean = np.reshape(cH.mean(axis=(1,2)), (n,1))\n",
    "    cV_mean = np.reshape(cV.mean(axis=(1,2)), (n,1))\n",
    "    cD_mean = np.reshape(cD.mean(axis=(1,2)), (n,1))\n",
    "    cA_var = np.reshape(cA.var(axis=(1,2)), (n,1))\n",
    "    cH_var = np.reshape(cH.var(axis=(1,2)), (n,1))\n",
    "    cV_var = np.reshape(cV.var(axis=(1,2)), (n,1))\n",
    "    cD_var = np.reshape(cD.var(axis=(1,2)), (n,1))\n",
    "    \n",
    "    Haar_wavelet_features = np.hstack((cA_mean,cH_mean,cV_mean,cD_mean,cA_var,cH_var,cV_var,cD_var))\n",
    "    return Haar_wavelet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new images for texture feature extraction\n",
    "ALL_0_texture = crop_image(ALL_0_gray, ALL_0_cx, ALL_0_cy)\n",
    "hem_0_texture = crop_image(hem_0_gray, hem_0_cx, hem_0_cy)\n",
    "test_texture = crop_image(test_gray, test_cx, test_cy)\n",
    "\n",
    "#F10-F22\n",
    "Haralick_all = Haralick(ALL_0_texture)\n",
    "Haralick_hem = Haralick(hem_0_texture)\n",
    "F10_F22_t = Haralick(test_texture)\n",
    "#F23-30\n",
    "Haar_wavelet_all = Haar_wavelet(ALL_0_texture)\n",
    "Haar_wavelet_hem = Haar_wavelet(hem_0_texture)\n",
    "F23_F30_t = Haar_wavelet(test_texture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color features\n",
    "def image_RGB_mean(image):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image in RGB\n",
    "    Return:\n",
    "        A tuple of (Red, Green, Blue) with mean value among all non-black pixels    \n",
    "    \"\"\"\n",
    "    flattened = image.reshape(-1, image.shape[-1])\n",
    "    RED, GREEN, BLUE = (0,1,2)\n",
    "    red_components = flattened[:, RED]\n",
    "    green_components = flattened[:, GREEN]\n",
    "    blue_components = flattened[:, BLUE]\n",
    "    mask = (red_components != 0) | (green_components != 0) | (blue_components != 0)\n",
    "    RGB_mean = np.mean(flattened[mask, :], axis = 0)\n",
    "    red, green, blue = RGB_mean[0], RGB_mean[1], RGB_mean[2]\n",
    "    return red, green, blue\n",
    "\n",
    "def image_HSV(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def image_HSV_mean(image):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image in HSV\n",
    "    Return:\n",
    "        A tuple of (Hue, Saturation, Value) with mean value among all non-black pixels    \n",
    "    \"\"\"\n",
    "    flattened = image.reshape(-1, image.shape[-1])\n",
    "    HUE, SATURATION, VALUE = (0,1,2)\n",
    "    hue_components = flattened[:, HUE]\n",
    "    saturation_components = flattened[:, SATURATION]\n",
    "    value_components = flattened[:, VALUE]\n",
    "    mask = (hue_components != 0) | (saturation_components != 0) | (value_components != 0)\n",
    "    HSV_mean = np.mean(flattened[mask, :], axis = 0)\n",
    "    hue, saturation, value = HSV_mean[0], HSV_mean[1], HSV_mean[2]\n",
    "    return hue, saturation, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F31-F36 color features\n",
    "F31_all = np.zeros(n_ALL)\n",
    "F32_all = np.zeros(n_ALL)\n",
    "F33_all = np.zeros(n_ALL)\n",
    "F31_hem = np.zeros(n_hem)\n",
    "F32_hem = np.zeros(n_hem)\n",
    "F33_hem = np.zeros(n_hem)\n",
    "F34_all = np.zeros(n_ALL)\n",
    "F35_all = np.zeros(n_ALL)\n",
    "F36_all = np.zeros(n_ALL)\n",
    "F34_hem = np.zeros(n_hem)\n",
    "F35_hem = np.zeros(n_hem)\n",
    "F36_hem = np.zeros(n_hem)\n",
    "for i in range(n_ALL):\n",
    "    F31_all[i],F32_all[i],F33_all[i] = image_RGB_mean(ALL_0_color[i])\n",
    "    ALL_HSV = image_HSV(ALL_0_color[i])\n",
    "    F34_all[i],F35_all[i],F36_all[i] = image_HSV_mean(ALL_HSV)\n",
    "for j in range(n_hem) :\n",
    "    F31_hem[j],F32_hem[j],F33_hem[j] = image_RGB_mean(hem_0_color[j])\n",
    "    hem_HSV = image_HSV(hem_0_color[j])\n",
    "    F34_hem[j],F35_hem[j],F36_hem[j] = image_HSV_mean(hem_HSV)\n",
    "    \n",
    "F31_t = np.zeros(n_test)\n",
    "F32_t = np.zeros(n_test)\n",
    "F33_t = np.zeros(n_test)\n",
    "F34_t = np.zeros(n_test)\n",
    "F35_t = np.zeros(n_test)\n",
    "F36_t = np.zeros(n_test)\n",
    "for i in range(n_test):\n",
    "    F31_t[i],F32_t[i],F33_t[i] = image_RGB_mean(test_color[i])\n",
    "    test_HSV = image_HSV(test_color[i])\n",
    "    F34_t[i],F35_t[i],F36_t[i] = image_HSV_mean(test_HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity(image):\n",
    "    \"\"\"\n",
    "    arg:\n",
    "        image: grayscale square iamges\n",
    "    returns: \n",
    "        mean: intensity mean of nonzero pixels\n",
    "        var: intensity variance of nonzero pixels\n",
    "    \"\"\"\n",
    "    shape = np.shape(image)\n",
    "    image = image.reshape(shape[0],shape[1]*shape[2])\n",
    "    mean = np.zeros((shape[0]),)\n",
    "    var = np.zeros((shape[0]),)\n",
    "    for i in range(shape[0]):\n",
    "        mask = (image[i] != 0)\n",
    "        mean[i] = np.mean(image[i,mask], axis=0)\n",
    "        var[i] = np.var(image[i,mask], axis=0)\n",
    "    return mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F37_all, F38_all = intensity(ALL_0_gray)\n",
    "F37_hem, F38_hem = intensity(hem_0_gray)\n",
    "F37_t, F38_t = intensity(test_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all features for training data\n",
    "ALL1 = np.stack((F1_all,F2_all,F3_all,F4_all,F5_all,F6_all,F7_all,F8_all,F9_all), axis=1)\n",
    "ALL3 = np.stack((F31_all,F32_all,F33_all,F34_all,F35_all,F36_all,F37_all,F38_all), axis=1)\n",
    "ALL = np.concatenate((ALL1,Haralick_all,Haar_wavelet_all,ALL3), axis=1)\n",
    "hem1 = np.stack((F1_hem,F2_hem,F3_hem,F4_hem,F5_hem,F6_hem,F7_hem,F8_hem,F9_hem), axis=1)\n",
    "hem3 = np.stack((F31_hem,F32_hem,F33_hem,F34_hem,F35_hem,F36_hem,F37_hem,F38_hem), axis=1)\n",
    "hem = np.concatenate((hem1,Haralick_hem,Haar_wavelet_hem,hem3), axis=1)\n",
    "print('Shape of ALL:', np.shape(ALL))\n",
    "print('Shape of hem:', np.shape(hem))\n",
    "\n",
    "# Combine ALL and hem \n",
    "raw_train_data = np.concatenate((ALL,hem), axis=0)\n",
    "\n",
    "print('Shape of training data:', np.shape(raw_train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature standardization\n",
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(raw_train_data)\n",
    "#data = StandardScaler().fit_transform(data)\n",
    "train_data\n",
    "\n",
    "# Conversion of data from numpy array to dataframe\n",
    "train_data_df = pd.DataFrame.from_records(train_data)\n",
    "train_data_df.columns = features\n",
    "label_train = np.concatenate(([1]*n_ALL,[0]*n_hem), axis=0) \n",
    "train_data_df.insert(0,\"Label\",label_train,True)\n",
    "\n",
    "# save train_data_df as a csv file\n",
    "train_data_df.to_csv(r'C:\\Users\\1000j\\CX4240+\\ProjectALL\\train_data.csv')\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comnine all features for test data\n",
    "test_data1 = np.stack((F1_t,F2_t,F3_t,F4_t,F5_t,F6_t,F7_t,F8_t,F9_t), axis=1)\n",
    "test_data3 = np.stack((F31_t,F32_t,F33_t,F34_t,F35_t,F36_t,F37_t,F38_t), axis=1)\n",
    "test_data = np.concatenate((test_data1,F10_F22_t,F23_F30_t,test_data3), axis=1)\n",
    "print('Shape of test data:', np.shape(test_data))\n",
    "\n",
    "# Feature standardization\n",
    "test_data = scaler.transform(test_data)\n",
    "test_data\n",
    "\n",
    "test_data_df = pd.DataFrame.from_records(test_data)\n",
    "test_data_df.columns = features\n",
    "\n",
    "# load labels for test data \n",
    "label_test_df = pd.read_csv (r'C:\\Users\\1000j\\CX4240+\\Cell_Images\\C-NMC_test_prelim_phase_data\\C-NMC_test_prelim_phase_data_labels.csv')\n",
    "print(label_test_df)\n",
    "label_test = label_test_df['labels'].as_matrix()\n",
    "test_data_df.insert(0,\"Label\",label_test_df['labels'],True)\n",
    "\n",
    "# save test_data_df as a csv file\n",
    "test_data_df.to_csv(r'C:\\Users\\1000j\\CX4240+\\ProjectALL\\test_data.csv')\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
